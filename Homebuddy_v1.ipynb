{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22079e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    make_scorer\n",
    ")\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment = pd.read_csv(r\"C:\\Users\\Ð¡ÐµÐ¼Ñ‘Ð½\\Desktop\\test task - data scientist\\infutor_enrichment_dataset.csv\")\n",
    "zipcode = pd.read_csv(r\"C:\\Users\\Ð¡ÐµÐ¼Ñ‘Ð½\\Desktop\\test task - data scientist\\zip_code_dataset.csv\")\n",
    "leads = pd.read_csv(r\"C:\\Users\\Ð¡ÐµÐ¼Ñ‘Ð½\\Desktop\\test task - data scientist\\leads_dataset.csv\")\n",
    "df = leads.merge(enrichment, how='left', on='HASHED_PHONE_NUMBER')\n",
    "df = df.merge(zipcode, how='left', on='ZIP_CODE')\n",
    "df['id'] = df['HASHED_PHONE_NUMBER'].astype(str) + ';' + \\\n",
    "           df['IS_APPOINTMENT_SET'].astype(str) + ';' + \\\n",
    "           df['LEAD_CREATED_AT_UTC'].astype(str)\n",
    "df = df.drop_duplicates(subset=['id'])\n",
    "df.shape\n",
    "reserve=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ccaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.columns\n",
    "print(\", \".join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256670e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_column(df, col):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Dtype: {df[col].dtype}\")\n",
    "    print(f\"Missing values: {df[col].isnull().sum()}\")\n",
    "    print(f\"Unique values: {df[col].nunique(dropna=True)}\")\n",
    "\n",
    "    examples = df[col].dropna().unique()\n",
    "    print(f\"All unique values: {examples}\")\n",
    "    \n",
    "\n",
    "    print(\"Top-5 most frequent values:\")\n",
    "    value_counts = df[col].value_counts(dropna=True).head(5)\n",
    "    for val, count in value_counts.items():\n",
    "        print(f\"  {repr(val)}: {count}\")\n",
    "\n",
    "for col in df.columns:\n",
    "    analyze_column(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values occurring in less than X% of cases,\n",
    "# to avoid class imbalance or perfect separation\n",
    "\n",
    "target_columns = ['STATE', 'EMAIL_DOMAIN', 'OPERATINGSYSTEMCLASS','OPERATINGSYSTEMNAME',\n",
    "                  'AGENTLANGUAGECODE', 'AGENTNAME','AGENTVERSIONMAJOR', 'DEVICEBRAND',\n",
    "                 'DEVICEFIRMWAREVERSION', 'DEVICENAME' ,'DEVICEVERSION',\n",
    "'FACEBOOKDEVICECLASS','LAYOUTENGINENAME','NETWORKTYPE',\n",
    "'OPERATINGSYSTEMVERSIONMAJOR','WEBVIEWAPPNAME','MATCHLEVEL']\n",
    "threshold = 0.1\n",
    "row_count = len(df)\n",
    "\n",
    "for col in target_columns:\n",
    "    value_counts = df[col].value_counts(normalize=True)\n",
    "    frequent_values = value_counts[value_counts >= threshold].index\n",
    "    df[col] = df[col].apply(lambda x: x if x in frequent_values else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4d146",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec31a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=['IS_APPOINTMENT_SET']).copy()\n",
    "df_clean['IS_APPOINTMENT_SET'] = df_clean['IS_APPOINTMENT_SET'].astype(int)\n",
    "use_cols =  [\n",
    "'IS_APPOINTMENT_SET', \n",
    "      'STATE', 'EMAIL_DOMAIN', 'OPERATINGSYSTEMCLASS','OPERATINGSYSTEMNAME',\n",
    "                  'AGENTLANGUAGECODE', 'AGENTNAME','AGENTVERSIONMAJOR', 'DEVICEBRAND',\n",
    "                 'DEVICEFIRMWAREVERSION', 'DEVICENAME' ,'DEVICEVERSION',\n",
    "'FACEBOOKDEVICECLASS','LAYOUTENGINENAME','NETWORKTYPE',\n",
    "'OPERATINGSYSTEMVERSIONMAJOR','WEBVIEWAPPNAME','MATCHLEVEL']\n",
    "\n",
    "df_small = df_clean[use_cols].copy()\n",
    "df_small = df_small.copy()\n",
    "df_small = df_small[df_small['IS_APPOINTMENT_SET'].notnull()]\n",
    "print(df_small.columns)\n",
    "y = df_small['IS_APPOINTMENT_SET'].astype(int)\n",
    "X = df_small.drop(columns=['IS_APPOINTMENT_SET'])\n",
    "categorical_cols = ['STATE', 'EMAIL_DOMAIN', 'OPERATINGSYSTEMCLASS','OPERATINGSYSTEMNAME',\n",
    "                  'AGENTLANGUAGECODE', 'AGENTNAME','AGENTVERSIONMAJOR', 'DEVICEBRAND',\n",
    "                 'DEVICEFIRMWAREVERSION', 'DEVICENAME' ,'DEVICEVERSION',\n",
    "'FACEBOOKDEVICECLASS','LAYOUTENGINENAME','NETWORKTYPE',\n",
    "'OPERATINGSYSTEMVERSIONMAJOR','WEBVIEWAPPNAME','MATCHLEVEL']\n",
    "print(categorical_cols)\n",
    "# numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols = []\n",
    "print(numerical_cols)\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# cat_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "# ])\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True, dtype=int))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_cols),\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=100,\n",
    "         fit_intercept=True,\n",
    "        solver='lbfgs',\n",
    "        multi_class='multinomial',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1] \n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6) \n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "print(f\"Threshold for Best F1-score: {best_threshold:.3f}\")\n",
    "print(f\"Best F1-score: {best_f1:.3f}\")\n",
    "\n",
    "\n",
    "y_pred_optimal = (y_proba >= best_threshold).astype(int)\n",
    "print(\"\\nðŸ“‹ Classification Report (Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð¿Ð¾Ñ€Ð¾Ð³Ð¾Ð¼):\")\n",
    "print(classification_report(y_test, y_pred_optimal))\n",
    "print(\"ðŸ“Š Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_optimal))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precision[1:], label='Accuracy', color='blue')\n",
    "plt.plot(thresholds, recall[1:], label='Recall', color='green')\n",
    "plt.plot(thresholds, f1_scores[1:], label='F1-score', color='red')\n",
    "plt.axvline(x=best_threshold, color='black', linestyle='--', label=f'Best threshold = {best_threshold:.2f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82277de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'saga'],\n",
    "    'classifier__max_iter': [100, 300, 1000]\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, average='macro') \n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=5,               \n",
    "    verbose=2,\n",
    "    n_jobs=-1           \n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(search.best_params_)\n",
    "print(\"Best F1-score:\")\n",
    "print(search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14199be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = model.named_steps['preprocessor'].transform(X_train)\n",
    "print(f\"Unique variables: {X_train_transformed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f5ccc",
   "metadata": {},
   "source": [
    "# LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeeed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=['IS_APPOINTMENT_SET']).copy()\n",
    "df_clean['IS_APPOINTMENT_SET'] = df_clean['IS_APPOINTMENT_SET'].astype(int)\n",
    "\n",
    "use_cols =  [\n",
    "'IS_APPOINTMENT_SET', \n",
    "      'STATE', 'EMAIL_DOMAIN', 'OPERATINGSYSTEMCLASS','OPERATINGSYSTEMNAME',\n",
    "                  'AGENTLANGUAGECODE', 'AGENTNAME','AGENTVERSIONMAJOR', 'DEVICEBRAND',\n",
    "                 'DEVICEFIRMWAREVERSION', 'DEVICENAME' ,'DEVICEVERSION',\n",
    "'FACEBOOKDEVICECLASS','LAYOUTENGINENAME','NETWORKTYPE',\n",
    "'OPERATINGSYSTEMVERSIONMAJOR','WEBVIEWAPPNAME','MATCHLEVEL']\n",
    "df_small = df_clean[use_cols].copy()\n",
    "\n",
    "\n",
    "y = df_small['IS_APPOINTMENT_SET']\n",
    "X = df_small.drop(columns=['IS_APPOINTMENT_SET'])\n",
    "\n",
    "\n",
    "categorical_cols = [ 'STATE', 'EMAIL_DOMAIN', 'OPERATINGSYSTEMCLASS','OPERATINGSYSTEMNAME',\n",
    "                  'AGENTLANGUAGECODE', 'AGENTNAME','AGENTVERSIONMAJOR', 'DEVICEBRAND',\n",
    "                 'DEVICEFIRMWAREVERSION', 'DEVICENAME' ,'DEVICEVERSION',\n",
    "'FACEBOOKDEVICECLASS','LAYOUTENGINENAME','NETWORKTYPE',\n",
    "'OPERATINGSYSTEMVERSIONMAJOR','WEBVIEWAPPNAME','MATCHLEVEL']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "model = LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=categorical_cols\n",
    ")\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_default = model.predict(X_test)\n",
    "\n",
    "print(\"Using default threshold (0.5):\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_pred_default))\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "print(f\"Best threshold for F1-score: {best_threshold:.3f}\")\n",
    "print(f\"Best F1-score: {best_f1:.3f}\")\n",
    "\n",
    "y_pred_optimal = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"Classification Report (best F1-Score):\")\n",
    "print(classification_report(y_test, y_pred_optimal))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_optimal))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precision[1:], label='Accuracy')\n",
    "plt.plot(thresholds, recall[1:], label='Recall')\n",
    "plt.plot(thresholds, f1_scores[1:], label='F1-score')\n",
    "plt.axvline(x=best_threshold, color='black', linestyle='--', label=f'Best threshold = {best_threshold:.2f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [ -1, 10, 20],\n",
    "    }\n",
    "model = LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train, categorical_feature=categorical_cols)\n",
    "\n",
    "print(f\"Best F1-score: {grid_search.best_score_:.4f}\")\n",
    "print(\"Best params:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ad429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# print(\"Accuracy Ð¿Ð¾ Ñ„Ð¾Ð»Ð´Ð°Ð¼:\", scores)\n",
    "# print(\"Ð¡Ñ€ÐµÐ´Ð½ÑÑ accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fdd63",
   "metadata": {},
   "source": [
    "# Analysis column by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols =  [\n",
    "    'IS_APPOINTMENT_SET',\n",
    "    'STATE',\n",
    "    'ZIP_CODE',\n",
    "    'ATTRIBUTES_COREDEMOGRAPHICS_GENDER',\n",
    "    'ATTRIBUTES_COREDEMOGRAPHICS_HOMEOWNERCD',\n",
    "    'OPERATINGSYSTEMCLASS',\n",
    "    'DEVICEBRAND',\n",
    "    'NETWORKTYPE',\n",
    "    'EMAIL_DOMAIN',\n",
    "\n",
    "       'ATTRIBUTES_COREDEMOGRAPHICS_DOB', \n",
    "       'ATTRIBUTES_COREDEMOGRAPHICS_MARRIEDCD',\n",
    "       'ATTRIBUTES_COREDEMOGRAPHICS_WEALTHSCR',\n",
    "        'ATTRIBUTES_COREDEMOGRAPHICS_EHI',\n",
    "    \n",
    "    \n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_FIREPLCD',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_POOL',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_CREDITCARD',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_HHNBRSR',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_YRBLD',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_LOR',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_HHNBR',\n",
    "    'ATTRIBUTES_SUPPLEMENTALDEMOGRAPHICS_CENS_POP_DENSITY',\n",
    "     'ATTRIBUTES_CONNEXSEGMENTATION_CT_HOMEIMPROVE12_ANY',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_HOMEREMODEL12_ANY',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_SOCIALUSAGE30_FB',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_SOCIALUSAGE30_INSTA',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_SOCIALUSAGE30_LNKIN',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_SOCIALUSAGE30_PINT',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_SOCIALUSAGE30_TWITTER',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_SOCIALUSAGE30_YOUTUBE',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_STRMSUB_HULU',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_STRMSUB_NETFLIX',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_ONLINESHOPSEG_DEALSEEK',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_ONLINESHOPSEG_OFFLINE',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_ONLINESHOPSEG_QUALSEEK',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_ONLINESHOPSEG_STRAITFWD',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_ONLINESHOPSEG_TRAD',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_MEDIA_HEAVYUSAGE_INTERNET',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_MEDIA_HEAVYUSAGE_MAGAZINE',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_MEDIA_HEAVYUSAGE_NEWSPAPER',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_MEDIA_HEAVYUSAGE_RADIO',\n",
    "    'ATTRIBUTES_CONNEXSEGMENTATION_CT_MEDIA_HEAVYUSAGE_TV',\n",
    "]\n",
    "\n",
    "def show(col):\n",
    "    print(f\"Column name: {col}\")\n",
    "    print(df[col].unique())\n",
    "    print(f\"NaNs: {len(df[df[col].isna()])}\")\n",
    "    print(df[col].value_counts())\n",
    "for col in use_cols:\n",
    "    show(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df)\n",
    "filled_counts = df.notna().sum()\n",
    "fill_percentage = (filled_counts / total_rows) * 100\n",
    "fill_percentage = fill_percentage.round(2)\n",
    "\n",
    "unique_counts = df.nunique(dropna=True)\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'column': fill_percentage.index,\n",
    "    'fill_%': fill_percentage.values,\n",
    "    'n_unique': unique_counts.values\n",
    "})\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8f2e1",
   "metadata": {},
   "source": [
    "# USERS WITH MORE THAN 1 ITERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['IS_APPOINTMENT_SET'].notna()]\n",
    "duplicate_counts = df1['HASHED_PHONE_NUMBER'].value_counts()\n",
    "duplicated_numbers = duplicate_counts[duplicate_counts > 1].index\n",
    "df_duplicates_only = df1[df1['HASHED_PHONE_NUMBER'].isin(duplicated_numbers)]\n",
    "df_duplicates_only['IS_APPOINTMENT_SET'] = df_duplicates_only['IS_APPOINTMENT_SET'].astype(int)\n",
    "df_duplicates_only.groupby('HASHED_PHONE_NUMBER')['IS_APPOINTMENT_SET'].sum().sort_values(ascending=False).reset_index(drop=False)[:10]\n",
    "df_duplicates_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_duplicates_only.copy()\n",
    "df['LEAD_CREATED_AT_UTC'] = pd.to_datetime(df['LEAD_CREATED_AT_UTC'])\n",
    "df_sorted = df.sort_values(by=['HASHED_PHONE_NUMBER', 'LEAD_CREATED_AT_UTC'])\n",
    "def assign_status_for_group(series):\n",
    "    first_val = series.iloc[0]\n",
    "    last_val = series.iloc[-1]\n",
    "    unique_vals = set(series)\n",
    "\n",
    "    if first_val == last_val:\n",
    "        if len(unique_vals) > 1:\n",
    "            return 'other'\n",
    "        else:\n",
    "            return f'all_{first_val}'\n",
    "    else:\n",
    "        if first_val == 1 and last_val == 0:\n",
    "            return '1->0'\n",
    "        elif first_val == 0 and last_val == 1:\n",
    "            return '0->1'\n",
    "        else:\n",
    "            return 'other'\n",
    "df_sorted['STATUS'] = df_sorted.groupby('HASHED_PHONE_NUMBER')['IS_APPOINTMENT_SET'].transform(assign_status_for_group)\n",
    "df_sorted['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcec83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNEXT STEPS\\nOptionA :\\n    Markov's equatations\\nOptionB:\\n    Cox model\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NEXT STEPS\n",
    "OptionA :\n",
    "    Markov's equatations\n",
    "OptionB:\n",
    "    Cox model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3cd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eca7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbb2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
